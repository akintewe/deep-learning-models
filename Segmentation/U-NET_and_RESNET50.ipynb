{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3599 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 8216s 72s/step - loss: 2.9971 - accuracy: 0.4251\n",
      "Epoch 2/10\n",
      " 71/113 [=================>............] - ETA: 52:52 - loss: 0.9451 - accuracy: 0.5845"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "train_dir = '/Users/nathan/Desktop/Code/Tomato-disease/training/PlantVillage/train'\n",
    "test_dir = '/Users/nathan/Desktop/Code/Tomato-disease/training/PlantVillage/validation'\n",
    "\n",
    "# U-Net model\n",
    "def create_unet_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Contracting path\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # Expanding path\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv2)\n",
    "    up1 = Conv2D(64, 2, activation='relu', padding='same')(up1)\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(up1)\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up2 = Conv2D(64, 2, activation='relu', padding='same')(up2)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    # Output\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(conv7)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create the U-Net model\n",
    "unet_model = create_unet_model(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES)\n",
    "\n",
    "# Create the ResNet50 model\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet', input_shape=(*IMAGE_SIZE, 3))\n",
    "\n",
    "# Freeze the layers of the ResNet50 model\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Get the output of the U-Net model\n",
    "unet_output = unet_model.output\n",
    "\n",
    "# Connect the output of the U-Net model to the input of the ResNet50 model\n",
    "resnet_input = resnet_model(unet_output)\n",
    "\n",
    "# Add a flatten layer and a dense layer on top of the ResNet50 model\n",
    "x = Flatten()(resnet_input)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = Model(inputs=unet_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the combined model\n",
    "combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the combined model\n",
    "history = combined_model.fit(\n",
    "    train_data,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# Evaluate the combined model\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loss, test_acc = combined_model.evaluate(test_data)\n",
    "\n",
    "# Plot the training accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Accuracy and Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Accuracy', 'Loss'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91392e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_recall_curve\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "# Get the predicted probabilities for each class\n",
    "y_pred_proba = combined_model.predict(test_data)\n",
    "y_pred_labels = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Get the true labels of the test data\n",
    "y_true_labels = test_data.classes\n",
    "\n",
    "# Calculate the validation loss\n",
    "val_loss = test_loss\n",
    "\n",
    "# Print the validation loss\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "\n",
    "y_true_one_hot = label_binarize(y_true_labels, classes=range(NUM_CLASSES))\n",
    "\n",
    "# Calculate and plot ROC curves for each class\n",
    "for class_index in range(NUM_CLASSES):\n",
    "    fpr, tpr, _ = roc_curve(y_true_one_hot[:, class_index], y_pred_proba[:, class_index])\n",
    "    plt.plot(fpr, tpr, label=f'Class {class_index}')\n",
    "\n",
    "plt.title('ROC Curves for Each Class')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "\n",
    "# Calculate class percentages\n",
    "class_counts = np.sum(y_true_one_hot, axis=0)\n",
    "class_percentages = class_counts / np.sum(class_counts)\n",
    "class_labels = [f'Class {i} ({percentage*100:.2f}%)' for i, percentage in enumerate(class_percentages)]\n",
    "\n",
    "# Show class percentages in the graph\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.text(0.5, 0.05, '\\n'.join(class_labels), horizontalalignment='center', verticalalignment='center',\n",
    "         transform=plt.gca().transAxes, bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "\n",
    "plt.show()\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate and plot precision-recall curves for each class\n",
    "for class_index in range(NUM_CLASSES):\n",
    "    y_true_binary = y_true_one_hot[:, class_index]\n",
    "    y_pred_binary = y_pred_proba[:, class_index]\n",
    "    precision = precision_score(y_true_binary, y_pred_binary)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary)\n",
    "    plt.plot(recall, precision, marker='o', markersize=5, label=f'Class {class_index}')\n",
    "\n",
    "plt.title('Precision-Recall Curves for Each Class')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bb729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
